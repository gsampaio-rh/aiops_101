{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. GraphRAG for Stock Exchange ITOps: Unlocking Relationships Between Services and Incidents\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the 10th notebook in our series on **AI for Stock Exchange IT Operations**! In this notebook, we explore the revolutionary potential of **Graph-based Retrieval-Augmented Generation (GraphRAG)** and demonstrate how it can uncover relationships in complex IT environments.\n",
    "\n",
    "By leveraging **GraphRAG**, IT operators can gain deep insights into service dependencies, configuration impacts, and historical incidents. This approach enhances traditional RAG techniques by incorporating graph structures to better represent interconnected systems, enabling precise and contextual retrieval of operational data.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. Understand the foundational principles of **GraphRAG** and how it differs from standard RAG.\n",
    "2. Explore how graphs model relationships in IT Operations (e.g., service dependencies, incident histories).\n",
    "3. Construct a graph-based knowledge base using service and incident data.\n",
    "4. Query the graph to retrieve actionable insights for ITOps tasks.\n",
    "5. Combine graph queries with LLMs to generate human-readable explanations and recommendations.\n",
    "\n",
    "### What Is GraphRAG?\n",
    "\n",
    "**GraphRAG** is an advanced variant of Retrieval-Augmented Generation (RAG) that incorporates **graph-based knowledge retrieval** into the workflow. Unlike traditional RAG, which relies on unstructured document retrieval, GraphRAG uses graph databases to model and query complex relationships between entities.\n",
    "\n",
    "#### Why GraphRAG?\n",
    "\n",
    "- **Relational Insights**: Graphs allow you to explicitly represent dependencies, hierarchies, and connections between entities like services, configurations, and incidents.\n",
    "- **Precision**: Queries target specific nodes and relationships, reducing ambiguity and noise in retrieval results.\n",
    "- **ITOps Relevance**: Perfect for environments with interconnected systems, such as stock exchanges, where understanding dependencies is critical.\n",
    "\n",
    "### How GraphRAG Works\n",
    "\n",
    "#### Step 1: Graph Construction\n",
    "- Use a graph database (e.g., Neo4j) to store relationships between services, incidents, and configurations.\n",
    "- Populate the graph with nodes (entities) and edges (relationships) extracted from IT operational data.\n",
    "\n",
    "#### Step 2: Graph Querying\n",
    "- Use graph queries (e.g., Cypher) to retrieve precise contextual data, such as impacted services or related incidents.\n",
    "\n",
    "#### Step 3: Integration with LLM\n",
    "- Feed the retrieved graph context into an LLM.\n",
    "- Generate clear and actionable insights, such as explanations of root causes or recommendations for configuration changes.\n",
    "\n",
    "### First Interaction with GraphRAG\n",
    "\n",
    "Letâ€™s dive into how GraphRAG works by building a simple knowledge graph for our stock exchange environment. In this example, we will:\n",
    "1. Construct a graph from service and incident data.\n",
    "2. Query the graph to retrieve relationships and dependencies.\n",
    "3. Use an LLM to provide explanations and actionable recommendations.\n",
    "\n",
    "![image](images/graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing the Required Libraries\n",
    "\n",
    "Before we start, we need to install the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community langchain-ollama langchain-experimental neo4j langchain_core --quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from neo4j import Driver\n",
    "from pydantic import BaseModel, Field\n",
    "from neo4j import GraphDatabase\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Neo4j Graph Database\n",
    "\n",
    "### Set Up Connection\n",
    "\n",
    "We first connect to the Neo4j database to prepare for storing and querying graph data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j successfully!\n"
     ]
    }
   ],
   "source": [
    "def initialize_graph_connection(uri: str, username: str, password: str):\n",
    "    \"\"\"Initializes connection to Neo4j graph database.\"\"\"\n",
    "    try:\n",
    "        graph = Neo4jGraph(url=uri, username=username, password=password)\n",
    "        print(\"Connected to Neo4j successfully!\")\n",
    "        return graph\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to Neo4j: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Connection Details\n",
    "URI = \"neo4j://localhost:7687\"\n",
    "USERNAME = \"neo4j\"\n",
    "PASSWORD = \"neo4jneo4j\"\n",
    "\n",
    "# Initialize Graph\n",
    "graph = initialize_graph_connection(URI, USERNAME, PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Split Text Data\n",
    "\n",
    "### Load Documents\n",
    "Load text data from a file to create graph nodes and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents.\n"
     ]
    }
   ],
   "source": [
    "# Load data from file\n",
    "loader = TextLoader(file_path=\"graph/post-mortem.txt\")\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Documents\n",
    "\n",
    "In real-world IT environments, operational data and incident reports are often lengthy and unstructured. To make this information usable for both graph-based analysis and AI processing:\n",
    "\n",
    "- **Improved Context Handling**: Splitting large documents ensures that each chunk contains focused and manageable information, making it easier for LLMs to understand and process context effectively.\n",
    "- **Efficient Graph Population**: Smaller chunks allow us to represent detailed relationships in the graph without overwhelming the structure with overly broad or ambiguous data.\n",
    "- **Scalability**: Processing smaller chunks reduces computational overhead and avoids issues with memory constraints or truncation limits of AI models.\n",
    "\n",
    "Below, we split the documents into smaller pieces, ensuring meaningful overlap between chunks to preserve context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split documents into 15 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Split text into manageable chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(documents=docs)\n",
    "print(f\"Split documents into {len(documents)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert Documents into Graph-Compatible Data\n",
    "\n",
    "Once we have split the documents into smaller, manageable chunks, the next step is to extract entities and relationships from the text. This is essential for building a graph that represents dependencies and connections in our stock exchange IT operations environment.\n",
    "\n",
    "### Why Use an LLM Transformer?\n",
    "\n",
    "- **Entity Extraction**: Identifies key entities such as services, incidents, and teams from the text.\n",
    "- **Relationship Discovery**: Maps connections between entities, providing a foundation for the graph.\n",
    "- **Contextual Graph Representation**: Converts unstructured text into structured, graph-compatible data.\n",
    "\n",
    "Below, we use the `LLMGraphTransformer` with the `OllamaFunctions` LLM to process the text chunks and generate graph documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaFunctions(model=\"llama3.1\", temperature=0, format=\"json\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDocument(nodes=[Node(id='Itops Team', type='Team', properties={}), Node(id='Stock Exchange', type='Organization', properties={})], relationships=[Relationship(source=Node(id='Itops Team', type='Team', properties={}), target=Node(id='Stock Exchange', type='Organization', properties={}), type='INCIDENT_RESPONSE', properties={})], source=Document(metadata={'source': 'graph/post-mortem.txt'}, page_content='### Post-Mortem Report for ItOps Team: Stock Exchange Incident'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Graph Documents to the Graph Database\n",
    "\n",
    "After converting the text documents into graph-compatible data, the next step is to populate the graph database with this information.\n",
    "\n",
    "#### Why Populate the Graph?\n",
    "- **Graph Representation**: The documents are transformed into nodes and relationships, creating a graph structure that models dependencies and interactions in the stock exchange IT environment.\n",
    "- **Query Capability**: Adding these documents allows us to query the graph for insights into service impacts, incidents, and more.\n",
    "- **Source Traceability**: By including the source text, we can trace each node and relationship back to its origin for deeper analysis.\n",
    "\n",
    "Below, we add the converted documents to the Neo4j graph, setting `baseEntityLabel` to create base nodes and `include_source` to retain the original context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents, baseEntityLabel=True, include_source=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating Embeddings and Vector Index for the Graph\n",
    "\n",
    "To enable efficient similarity-based retrieval of graph nodes, we generate embeddings for the text data and create a vector index. This allows us to:\n",
    "\n",
    "- **Enhance Search**: Retrieve relevant nodes based on vector similarity, useful for finding related incidents or services.\n",
    "- **Hybrid Search**: Combine traditional graph queries with vector-based retrieval for more robust results.\n",
    "- **AI-Driven Contextual Queries**: Use embeddings to find semantically similar nodes, enhancing the capability of GraphRAG.\n",
    "\n",
    "Below, we:\n",
    "1. Use the `OllamaEmbeddings` model to generate embeddings for the graph data.\n",
    "2. Create a vector index in Neo4j using the `Neo4jVector` module.\n",
    "3. Configure a retriever for querying the vector index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"mxbai-embed-large\",\n",
    ")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    url=URI,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    ")\n",
    "vector_retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating a Full-Text Index in the Graph Database\n",
    "\n",
    "To enable efficient text-based searches, we create a **full-text index** in the Neo4j database. This allows for:\n",
    "\n",
    "- **Improved Search Performance**: Quickly retrieve nodes based on their properties.\n",
    "- **Enhanced Query Capabilities**: Use full-text search to find entities or relationships by their descriptions or identifiers.\n",
    "\n",
    "Below, we define a Cypher query to create a full-text index on the `id` property of nodes labeled `__Entity__`. This will help us efficiently search for entities in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating full-text index: {code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent index already exists, 'Index( id=7, name='fulltext_entity_id', type='FULLTEXT', schema=(:__Entity__ {id}), indexProvider='fulltext-1.0' )'.}\n"
     ]
    }
   ],
   "source": [
    "# Authentication credentials\n",
    "AUTH = (USERNAME, PASSWORD)\n",
    "\n",
    "# Establish a connection to the Neo4j driver\n",
    "driver = GraphDatabase.driver(\n",
    "    uri=URI,\n",
    "    auth=AUTH,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to create a full-text index\n",
    "def create_fulltext_index(tx):\n",
    "    query = \"\"\"\n",
    "    CREATE FULLTEXT INDEX `fulltext_entity_id` \n",
    "    FOR (n:__Entity__) \n",
    "    ON EACH [n.id];\n",
    "    \"\"\"\n",
    "    tx.run(query)\n",
    "\n",
    "\n",
    "# Wrapper function to execute the query\n",
    "def create_index():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_fulltext_index)\n",
    "        print(\"Full-text index created successfully.\")\n",
    "\n",
    "\n",
    "# Attempt to create the full-text index\n",
    "try:\n",
    "    create_index()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating full-text index: {e}\")\n",
    "\n",
    "# Close the Neo4j driver connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Defining the Entity Extraction Class and Prompt\n",
    "\n",
    "To extract key entities (such as incidents, systems, teams, and protocols) from the text, we define:\n",
    "\n",
    "1. **`Entities` Class**: A Pydantic model to specify the schema of the extracted entities.\n",
    "2. **Prompt Template**: A structured prompt for the LLM, instructing it to focus on extracting relevant entities for stock exchange incident management.\n",
    "\n",
    "This approach ensures that the LLM produces well-structured outputs, aligning with the graph schema for seamless integration.\n",
    "\n",
    "Below, we set up the `Entities` class and the `ChatPromptTemplate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the relevant entities, such as incidents, systems, teams, or protocols, \"\n",
    "        \"that appear in the text.\",\n",
    "    )\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Your task is to extract key entities related to stock exchange incident management. \"\n",
    "            \"Focus on identifying incidents, systems, teams, protocols, and any related actions or impacts \"\n",
    "            \"from the provided text. Ensure the extracted entities align with the database schema \"\n",
    "            \"and are relevant to troubleshooting and resolution.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "entity_chain = llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entities(names=['Infrastructure Team'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_chain.invoke(\n",
    "    \"Who's the Infrastructure Team?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retrieving Graph Data Based on Full-Text Index and Entities\n",
    "\n",
    "The `graph_retriever` function performs the following tasks:\n",
    "\n",
    "1. **Entity Extraction**: It uses the `entity_chain` to extract relevant entities from the input question.\n",
    "2. **Full-Text Search**: Queries the Neo4j full-text index (`fulltext_entity_id`) to locate nodes related to the extracted entities.\n",
    "3. **Neighborhood Exploration**: Collects the relationships (edges) between the retrieved nodes and their neighbors.\n",
    "\n",
    "This approach ensures that the retrieved data is relevant to the user's query, focusing on the entities and their connections in the graph.\n",
    "\n",
    "Below is the implementation of the `graph_retriever` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fulltext index query\n",
    "def graph_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke(question)\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": entity},\n",
    "        )\n",
    "        result += \"\\n\".join([el[\"output\"] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itops Team - INCIDENT_RESPONSE -> Stock Exchange\n",
      "Team Training On Incident Response - ASSIGNED_TO -> Training Coordinator\n"
     ]
    }
   ],
   "source": [
    "print(graph_retriever(\"Who's the Infrastructure Team?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Graph and Vector Retrieval for Enhanced Context\n",
    "\n",
    "The `full_retriever` function combines:\n",
    "\n",
    "1. **Graph Retrieval**: Uses the `graph_retriever` function to extract relationships and entities from the graph database.\n",
    "2. **Vector Retrieval**: Leverages the vector retriever to find semantically similar documents based on the input question.\n",
    "\n",
    "By merging these two approaches, this function provides comprehensive and contextual information that can be used by an LLM for generating insights and recommendations.\n",
    "\n",
    "#### Output Structure\n",
    "The combined output includes:\n",
    "- **Graph Data**: Relationships and entities retrieved from the graph.\n",
    "- **Vector Data**: Semantically similar document content retrieved using embeddings.\n",
    "\n",
    "Below is the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_retriever(question: str):\n",
    "    graph_data = graph_retriever(question)\n",
    "    vector_data = [el.page_content for el in vector_retriever.invoke(question)]\n",
    "    final_data = f\"\"\"Graph data:\n",
    "{graph_data}\n",
    "vector data:\n",
    "{\"#Document \". join(vector_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Creating and Executing the Query Chain\n",
    "\n",
    "The query chain integrates all the components into a seamless pipeline for answering questions:\n",
    "\n",
    "1. **Context Generation**: Combines graph-based and vector-based retrieval using the `full_retriever` function to provide rich contextual information.\n",
    "2. **Prompt Template**: A predefined template instructs the LLM to focus on the given context and provide concise answers.\n",
    "3. **Execution Chain**: The pipeline connects the context generator, prompt template, and LLM to process queries end-to-end.\n",
    "\n",
    "### Key Features\n",
    "- **Natural Language Responses**: The output is optimized for readability and clarity.\n",
    "- **Conciseness**: The LLM is instructed to generate brief yet informative answers.\n",
    "- **Integration**: Combines structured graph data with unstructured vector-based retrieval for robust insights.\n",
    "\n",
    "Below is the implementation of the chain and an example query execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be concise.\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": full_retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Infrastructure Team fixed database failover configuration, promoted a secondary node to restore operations, cleared transaction backlogs without inconsistencies, and communicated updates to stakeholders.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    input=\"What the Infrastructure Team did?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "In this notebook, we explored how to use **GraphRAG** to enhance IT operations for stock exchanges by combining graph-based knowledge retrieval and LLMs. This approach provided a robust framework for uncovering relationships between services, incidents, and dependencies in complex IT environments.\n",
    "\n",
    "### Key Highlights\n",
    "1. **Graph-Based Context Retrieval**:\n",
    "   - By constructing and querying a graph database, we modeled dependencies and interactions between services, configurations, and incidents, enabling precise and context-aware retrieval of data.\n",
    "2. **Seamless Integration with LLMs**:\n",
    "   - We combined graph retrieval with vector-based document search to provide a rich, comprehensive context, allowing LLMs to generate concise and actionable insights.\n",
    "3. **Enhanced Operational Insights**:\n",
    "   - Through the pipeline, we demonstrated how IT operators can ask natural language questions and receive clear explanations and recommendations to address system incidents.\n",
    "\n",
    "### What's Next?\n",
    "In the next notebook, we will:\n",
    "1. **Expand the GraphRAG Workflow**:\n",
    "   - Introduce more advanced query capabilities and visualization tools for exploring the graph structure and relationships.\n",
    "2. **Focus on Incident Automation**:\n",
    "   - Use AI agents to proactively trigger incident remediation actions based on the insights retrieved from the graph.\n",
    "3. **Integrate Advanced Models**:\n",
    "   - Experiment with transformer-based models to enhance the reasoning and contextual understanding of operational data, further improving the accuracy and relevance of the recommendations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
