{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Transformers for Kubernetes Operations: Enhancing Prediction Accuracy with NLP\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the 8th notebook in our series on **AI for Kubernetes operations**! In the previous notebook, we explored the basics of **machine learning** and applied a **Decision Tree Classifier** to predict Kubernetes incidents. Now, we’ll dive deeper into a more advanced approach using **transformer models** like **BERT** to enhance the prediction accuracy for Kubernetes incidents.\n",
    "\n",
    "Transformer models have revolutionized the field of Natural Language Processing (NLP) and can also be leveraged for tasks like classifying Kubernetes events based on operational metrics and logs. In this notebook, we will explore how to fine-tune a pre-trained transformer model, BERT (Bidirectional Encoder Representations from Transformers), for the task of event classification in Kubernetes operations.\n",
    "\n",
    "By using BERT, we aim to leverage its ability to understand contextual relationships in text-based data to classify events more accurately and robustly.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Understand the key concepts behind transformer models and BERT.\n",
    "- Fine-tune a pre-trained BERT model on Kubernetes operational data.\n",
    "- Evaluate the model's performance using standard classification metrics.\n",
    "- Interpret results and visualize the predictions using confusion matrices and classification reports.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "This notebook introduces:\n",
    "- An introduction to **transformer models** and their applications in AI and NLP.\n",
    "- A hands-on guide to **fine-tuning BERT** on Kubernetes operational data for event classification.\n",
    "- Evaluation and interpretation of model performance:\n",
    "  - Classification reports to understand model accuracy and performance.\n",
    "  - Confusion matrices to identify misclassifications and improve model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing the Required Libraries\n",
    "\n",
    "Before we start, we need to install the necessary libraries. These include **transformers**, **torch**, and **scikit-learn**, which are required to build and fine-tune the BERT model. Run the following cell to install these libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch scikit-learn matplotlib seaborn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Information\n",
    "\n",
    "In this section, we check the environment in which we are running the code. This includes the Python version, PyTorch version, and whether a compatible GPU or Apple MPS is available.\n",
    "\n",
    "This helps us ensure that we are leveraging the best computational resources for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-15.2-arm64-arm-64bit\n",
      "PyTorch Version: 2.5.1\n",
      "\n",
      "Python 3.12.4 (main, Jun  6 2024, 18:26:44) [Clang 15.0.0 (clang-1500.3.9.4)]\n",
      "Pandas 2.2.3\n",
      "Scikit-Learn 1.6.1\n",
      "NVIDIA/CUDA GPU is NOT AVAILABLE\n",
      "MPS (Apple Metal) is AVAILABLE\n",
      "Target device is mps\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import platform\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    ")\n",
    "\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"NVIDIA/CUDA GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AVAILABLE\")\n",
    "print(f\"Target device is {device}\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and Preparing the Dataset\n",
    "\n",
    "In this section, we load the preprocessed Kubernetes dataset that contains event information and operational metrics. We combine the relevant event columns into a single target column (`event_message`) and encode it for use with BERT. \n",
    "\n",
    "This dataset will be used to fine-tune the BERT model for classifying Kubernetes events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"data/preprocessed_kubernetes_data.csv\"  # Update with the correct path\n",
    "df = pd.read_csv(file_path, parse_dates=[\"timestamp\"], index_col=\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoding the Target Labels\n",
    "\n",
    "In this step, we transform the event labels (like `Normal`, `Warning`, `Error`) into numeric values. This transformation is necessary because machine learning models, including BERT, work with numerical data, not categorical strings.\n",
    "\n",
    "- **Label Encoding**: The `LabelEncoder` from `sklearn` is used to convert the string labels into integers (e.g., `Normal` -> 0, `Warning` -> 1, `Error` -> 2). This allows the model to understand and process the data.\n",
    "- **BERT Processing**: BERT and other machine learning models expect the target labels to be in a numerical format for tasks like classification. The encoding ensures that the model can learn to predict the correct event type.\n",
    "\n",
    "By encoding the labels, we make the dataset ready for training with a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine event-related columns into a single target column\n",
    "event_columns = [\n",
    "    \"event_message_Completed\",\n",
    "    \"event_message_Failed\",\n",
    "    \"event_message_Killed\",\n",
    "    \"event_message_OOMKilled\",\n",
    "    \"event_message_Started\",\n",
    "    \"event_type_Error\",\n",
    "    \"event_type_Normal\",\n",
    "    \"event_type_Warning\",\n",
    "]\n",
    "\n",
    "df[\"event_message\"] = df[event_columns].idxmax(axis=1)  # get the event type\n",
    "df[\"event_message\"] = (\n",
    "    df[\"event_message\"].str.replace(\"event_message_\", \"\").str.replace(\"event_type_\", \"\")\n",
    ")\n",
    "df.drop(columns=event_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"event_message_encoded\"] = label_encoder.fit_transform(df[\"event_message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Selecting Features and Target Variable\n",
    "\n",
    "In this section, we define the **features** (inputs) and the **target variable** (output) that our model will use for training.\n",
    "\n",
    "- **Feature Selection**: The features describe the state of the system and its health. By selecting the right features, the model can learn patterns that help predict Kubernetes events.\n",
    "- **Target Variable**: This tells the model what to predict (event type), and it is encoded numerically to make the data easier to work with.\n",
    "\n",
    "Together, these features and the target variable provide the necessary data for the model to train and make predictions on Kubernetes events.\n",
    "\n",
    "### Numerical Features\n",
    "The features selected are important Kubernetes operational metrics, including:\n",
    "- `cpu_allocation_efficiency`: How efficiently CPU resources are used.\n",
    "- `memory_allocation_efficiency`: How efficiently memory is used.\n",
    "- `disk_io`: Rate of data transfer to/from the disk.\n",
    "- `network_latency`: Delay in network communication.\n",
    "- `node_temperature`: Temperature of the node, which can affect performance.\n",
    "- `node_cpu_usage`: Percentage of CPU used on the node.\n",
    "- `node_memory_usage`: Amount of memory used on the node.\n",
    "\n",
    "These features are essential because they help the model understand the conditions in which various Kubernetes events (such as `Normal`, `Warning`, or `Error`) occur.\n",
    "\n",
    "### Target Variable\n",
    "The target variable, `event_message_encoded`, represents the event type (e.g., `Normal`, `Warning`, `Error`). The target is encoded into numerical values so that the model can learn to predict event types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"cpu_allocation_efficiency\",\n",
    "    \"memory_allocation_efficiency\",\n",
    "    \"disk_io\",\n",
    "    \"network_latency\",\n",
    "    \"node_temperature\",\n",
    "    \"node_cpu_usage\",\n",
    "    \"node_memory_usage\",\n",
    "]\n",
    "\n",
    "# Select features\n",
    "X = df[numerical_features]\n",
    "y = df[\"event_message_encoded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tokenizing the Event Messages\n",
    "\n",
    "In this step, we prepare the text data (event messages) for input into the BERT model by using the **BERT tokenizer**. The tokenizer converts the raw text into token IDs that represent words or subwords, allowing BERT to process the text.\n",
    "\n",
    "- **BERT Tokenizer**: The tokenizer splits the event messages into subwords or words and then converts them into corresponding token IDs. This is necessary because BERT understands the text in the form of token IDs, not raw text.\n",
    "- **Padding**: Since BERT expects all input sequences to be of the same length, we apply padding to ensure that all event messages are of uniform length (e.g., 128 tokens). If a message is shorter, it is padded with zeros to match the desired length.\n",
    "- **Attention Masks**: Attention masks indicate which tokens are actual data (1) and which ones are padding (0). This helps the model focus on the real tokens during processing and ignore the padding tokens.\n",
    "\n",
    "By tokenizing, padding, and creating attention masks, we prepare the text data in a format that BERT can efficiently process for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the event message (for BERT)\n",
    "X_text = df[\"event_message\"].apply(\n",
    "    lambda x: tokenizer.encode(x, truncation=True, padding=\"max_length\", max_length=128)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding and attention mask\n",
    "def create_attention_mask(input_ids):\n",
    "    attention_mask = [1 if token_id > 0 else 0 for token_id in input_ids]\n",
    "    return attention_mask\n",
    "\n",
    "\n",
    "X_text_pad = torch.tensor(\n",
    "    [x + [0] * (128 - len(x)) if len(x) < 128 else x[:128] for x in X_text]\n",
    ")  # Padding\n",
    "attention_masks = torch.tensor([create_attention_mask(x) for x in X_text_pad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training the BERT Model\n",
    "\n",
    "In this step, we initiate the **training process** for the BERT model. The model learns to classify Kubernetes events based on operational metrics by adjusting its weights to minimize prediction errors.\n",
    "\n",
    "### Key Components of the Training Process:\n",
    "- **Training Loop**: The model is trained over multiple epochs, where each epoch consists of several batches of data. During each epoch, the model learns from the training data and updates its parameters to improve performance.\n",
    "- **tqdm**: We use **tqdm** to track the progress of the training loop. It provides a progress bar that shows the number of batches processed, the current epoch, and key metrics such as loss and accuracy.\n",
    "- **Loss Function**: We use **CrossEntropyLoss** as the loss function. This function computes the difference between the predicted class probabilities and the actual labels, guiding the model in adjusting its parameters to minimize the error.\n",
    "- **Accuracy Calculation**: After each epoch, we calculate the model’s accuracy by comparing its predictions with the true labels. This helps us monitor the model's performance over time.\n",
    "\n",
    "During training, the model adjusts its internal weights to better understand how operational metrics influence event types, improving its ability to classify Kubernetes incidents accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Splitting the Data into Training and Testing Sets\n",
    "\n",
    "In this step, we **split the dataset** into two parts: one for training the model and another for testing its performance. This is essential to evaluate how well the model generalizes to unseen data.\n",
    "\n",
    "### Key Actions:\n",
    "- **train_test_split**: We use the `train_test_split` function from **scikit-learn** to randomly divide the data into training and testing sets. The training set is used to teach the model, while the testing set is used to evaluate the model's performance. We allocate 80% of the data for training and 20% for testing, ensuring a balanced split.\n",
    "  \n",
    "- **TensorDataset**: We convert the data into **TensorDataset** objects, which are compatible with PyTorch’s **DataLoader**. This allows the model to efficiently access the training and testing data during training and evaluation.\n",
    "  \n",
    "- **DataLoader**: The **DataLoader** provides an iterable over the dataset, splitting it into batches of a specified size (32 in this case). This is crucial for handling large datasets, as it allows the model to process data in manageable chunks, updating its weights incrementally.\n",
    "\n",
    "This step prepares the data for feeding into the BERT model, ensuring that the model can efficiently process both the text data and the operational metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_text_pad, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Convert to TensorDataset for DataLoader\n",
    "train_data = TensorDataset(\n",
    "    X_train, attention_masks[: len(X_train)], torch.tensor(y_train.values)\n",
    ")\n",
    "test_data = TensorDataset(\n",
    "    X_test, attention_masks[len(X_train) :], torch.tensor(y_test.values)\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Initializing the BERT Model for Sequence Classification\n",
    "\n",
    "In this step, we initialize the **BERT model** to perform sequence classification, which is essential for classifying the Kubernetes event types based on the input data.\n",
    "\n",
    "### Key Actions:\n",
    "- **BERT Model Initialization**: We load a pre-trained version of **BERT** (`bert-base-uncased`) using the `BertForSequenceClassification` class. This class is specifically designed for text classification tasks. We set the `num_labels` argument to match the number of unique event types, ensuring the model outputs the correct number of class predictions (e.g., Normal, Warning, Error).\n",
    "  \n",
    "- **Adam Optimizer**: The **AdamW** optimizer is used to update the model’s weights during training. We set the learning rate to `1e-5` to ensure the model learns effectively without overshooting the optimal weights. Adam is widely used for its ability to adapt the learning rate for each parameter.\n",
    "  \n",
    "- **Moving to GPU/CPU**: The model is moved to the available device (GPU or CPU) using `model.to(device)`. This is important because training deep learning models can be computationally intensive, and using a GPU can significantly speed up the process.\n",
    "\n",
    "By setting up the BERT model in this way, we are ready to begin training it on the dataset to classify the Kubernetes events based on both the text and operational features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/gsampaio/redhat/ai/aiops_101/.venv/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=len(label_encoder.classes_)\n",
    ")\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Training the BERT Model\n",
    "\n",
    "Now, we proceed with the training of the BERT model using the dataset. The training loop involves multiple key steps to update the model’s parameters and evaluate its performance.\n",
    "\n",
    "### Key Steps:\n",
    "1. **Optimizer and Loss Function Setup**:\n",
    "   - We use the **AdamW** optimizer with a learning rate of `2e-5`. This optimizer adapts the learning rate for each model parameter, helping the model converge efficiently during training.\n",
    "   - The **CrossEntropyLoss** function is chosen as the loss function, which is suitable for multi-class classification tasks like predicting the Kubernetes event type.\n",
    "\n",
    "2. **Epoch Loop**:\n",
    "   - The model is trained for a total of **3 epochs**. Each epoch represents a complete pass through the training data. During each epoch, the model learns from the training data and adjusts its weights to minimize the loss.\n",
    "   \n",
    "3. **Training Data Loop**:\n",
    "   - For each batch in the **training data**, we:\n",
    "     - Transfer the data to the GPU or CPU (`to(device)`).\n",
    "     - Perform a **forward pass** through the model to get the predicted logits (raw outputs from the model).\n",
    "     - **Calculate the loss** by comparing the predicted logits with the true labels.\n",
    "     - Perform a **backward pass** to compute gradients and **update the model's weights** using the optimizer.\n",
    "\n",
    "4. **Tracking Performance**:\n",
    "   - We track the running loss and accuracy throughout the training loop. The **accuracy** is calculated by comparing the predicted labels (`preds`) with the true labels (`labels`) in each batch.\n",
    "   - After each epoch, the average loss and accuracy for the epoch are displayed, providing feedback on the model’s progress.\n",
    "\n",
    "5. **Validation (optional)**:\n",
    "   - After training each epoch, we evaluate the model on the **test dataset**. This helps check how well the model generalizes to unseen data.\n",
    "   - We calculate **validation loss** and **validation accuracy** in the same way as during training.\n",
    "\n",
    "This process allows the model to progressively learn from the data, improving its ability to classify Kubernetes events correctly over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 375/375 [02:50<00:00,  2.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.1112, Accuracy: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 94/94 [00:13<00:00,  6.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0034, Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 375/375 [03:18<00:00,  1.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 0.0031, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 94/94 [00:14<00:00,  6.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0012, Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 375/375 [03:19<00:00,  1.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 0.0014, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 94/94 [00:15<00:00,  5.90batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0007, Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 3\n",
    "\n",
    "# Training loop with tqdm progress bar\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Loop through training data with progress bar\n",
    "    for batch in tqdm(\n",
    "        train_dataloader, desc=f\"Training Epoch {epoch + 1}\", unit=\"batch\"\n",
    "    ):\n",
    "        # Get the data for the current batch\n",
    "        input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get predictions and calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    # Calculate and print the epoch loss and accuracy\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Epoch {epoch + 1} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Validation (optional)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_predictions = 0\n",
    "        for batch in tqdm(test_dataloader, desc=\"Validating\", unit=\"batch\"):\n",
    "            input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            val_correct_predictions += torch.sum(preds == labels)\n",
    "            val_total_predictions += labels.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_dataloader)\n",
    "        val_accuracy = val_correct_predictions / val_total_predictions\n",
    "        print(\n",
    "            f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluating the Model\n",
    "\n",
    "Once the model is trained, it's crucial to evaluate its performance on the **test set**. This evaluation helps us understand how well the model generalizes to new, unseen data. The two primary tools we use for evaluating model performance are **classification reports** and **confusion matrices**.\n",
    "\n",
    "\n",
    "2. **Confusion Matrix**:\n",
    "   - The confusion matrix visualizes the model’s prediction errors and successes. It shows how many instances from each class were correctly predicted (True Positives and True Negatives) and how many were misclassified (False Positives and False Negatives).\n",
    "   - By examining the confusion matrix, we can identify which event types the model struggles to classify, giving insight into areas where the model needs improvement.\n",
    "\n",
    "By analyzing the classification report and confusion matrix, we can assess the model's overall effectiveness, detect potential issues like class imbalances, and refine the model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Convert logits to predicted class labels\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Mapping back the numeric predictions to original class labels\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "y_true_labels = label_encoder.inverse_transform(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Classification Report\n",
    "\n",
    "- The classification report provides a detailed breakdown of the model’s performance across each class (in this case, the different event types).\n",
    "- It includes metrics like **precision**, **recall**, **f1-score**, and **support**:\n",
    "    - **Precision**: The percentage of positive predictions that are correct.\n",
    "    - **Recall**: The percentage of actual positive instances that were correctly identified.\n",
    "    - **F1-score**: The harmonic mean of precision and recall, providing a single metric that balances both.\n",
    "    - **Support**: The number of occurrences of each class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Completed       1.00      1.00      1.00       608\n",
      "      Failed       1.00      1.00      1.00       593\n",
      "      Killed       1.00      1.00      1.00       574\n",
      "   OOMKilled       1.00      1.00      1.00       621\n",
      "     Started       1.00      1.00      1.00       604\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Confusion Matrix:\n",
    "\n",
    "- The confusion matrix visualizes the model’s prediction errors and successes. It shows how many instances from each class were correctly predicted (True Positives and True Negatives) and how many were misclassified (False Positives and False Negatives).\n",
    "- By examining the confusion matrix, we can identify which event types the model struggles to classify, giving insight into areas where the model needs improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we leveraged **BERT**, a powerful transformer model, to classify Kubernetes events. We fine-tuned the model using operational metrics and event data and evaluated its performance using standard classification metrics like accuracy, precision, and recall.\n",
    "\n",
    "### Key Takeaways:\n",
    "- **BERT** is highly effective at capturing contextual relationships in text and can be applied to a wide range of event classification tasks.\n",
    "- The model was evaluated using **classification reports** and **confusion matrices** to understand its accuracy and identify potential improvements.\n",
    "- Fine-tuning transformer models like BERT offers significant advantages over traditional machine learning models, particularly when working with text data.\n",
    "\n",
    "### What's Next?\n",
    "In the next notebook, we will explore more advanced transformer models and their applications in Kubernetes operations. We will also experiment with different architectures to improve classification performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
