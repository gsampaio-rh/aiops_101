{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Transformers for Kubernetes Operations: Enhancing Prediction Accuracy with NLP\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the 8th notebook in our series on **AI for Kubernetes operations**! In this notebook, we take a leap into cutting-edge AI techniques by leveraging **transformer models** like **BERT** for Kubernetes event classification. \n",
    "\n",
    "Transformers are a revolutionary class of models that have redefined how machines process sequential data, particularly in natural language processing (NLP). Their ability to capture **contextual relationships** in text makes them highly effective for understanding Kubernetes operational data, such as logs and events.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand the foundational concepts behind transformer models and their advantages over traditional approaches.\n",
    "2. Fine-tune a pretrained transformer model (**BERT**) for Kubernetes event classification.\n",
    "3. Evaluate the model's performance using metrics such as accuracy, precision, recall, and confusion matrices.\n",
    "\n",
    "### What Are Transformers, and Why Do They Matter?\n",
    "\n",
    "Transformers are advanced neural network architectures designed to process and analyze sequential data. Unlike traditional sequence models like LSTMs or RNNs, transformers use a mechanism called **self-attention** to understand relationships between different parts of the input sequence.\n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png\" alt=\"The encoder-decoder structure of the Transformer architecture\" width=\"600\"/>\n",
    "<p><em>Source: Attention Is All You Need, 2017.</em></p>\n",
    "\n",
    "#### Key Features of Transformers:\n",
    "1. **Self-Attention**: Captures dependencies between words, regardless of their position in the sequence.\n",
    "   - Example: In the phrase \"The pod crashed because it ran out of memory,\" transformers link \"crashed\" with \"ran out of memory\" even though the words are separated.\n",
    "2. **Parallel Processing**: Unlike RNNs, transformers process input sequences in parallel, making them faster and more scalable.\n",
    "3. **Pretrained Models**: Models like **BERT** come pretrained on massive datasets, enabling them to quickly adapt to specific tasks with minimal additional training.\n",
    "\n",
    "#### Why Do Transformers Exist?\n",
    "Transformers were introduced to overcome the limitations of earlier sequence models, which struggled with:\n",
    "- Capturing long-range dependencies in text.\n",
    "- Training inefficiencies due to sequential data processing.\n",
    "\n",
    "By addressing these issues, transformers enable:\n",
    "- **Faster Training**: Thanks to parallelization.\n",
    "- **Better Context Understanding**: Through self-attention.\n",
    "\n",
    "### Relevance to Kubernetes Operations\n",
    "\n",
    "Kubernetes environments generate vast amounts of sequential data, such as:\n",
    "- **Logs**: Event logs describing system behaviors (e.g., \"Pod restarted due to memory exhaustion\").\n",
    "- **Metrics**: Time-series data on resource utilization (e.g., CPU usage, memory allocation).\n",
    "\n",
    "Transformers, particularly models like **BERT**, excel in understanding the context within such text-based data. For example:\n",
    "- **Use Case**: Classifying Kubernetes events (e.g., Normal, Warning, Error) based on operational logs.\n",
    "- **Benefit**: Accurately identifying and categorizing events helps operators prioritize and respond to critical issues faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing the Required Libraries\n",
    "\n",
    "Before we start, we need to install the necessary libraries. These include **transformers**, **torch**, and **scikit-learn**, which are required to build and fine-tune the BERT model. Run the following cell to install these libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch scikit-learn matplotlib seaborn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Information\n",
    "\n",
    "In this section, we check the environment in which we are running the code. This includes the Python version, PyTorch version, and whether a compatible GPU or Apple MPS is available.\n",
    "This helps us ensure that we are leveraging the best computational resources for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-15.2-arm64-arm-64bit\n",
      "PyTorch Version: 2.5.1\n",
      "\n",
      "Python 3.12.4 (main, Jun  6 2024, 18:26:44) [Clang 15.0.0 (clang-1500.3.9.4)]\n",
      "Pandas 2.2.3\n",
      "Scikit-Learn 1.6.1\n",
      "NVIDIA/CUDA GPU is NOT AVAILABLE\n",
      "MPS (Apple Metal) is AVAILABLE\n",
      "Target device is mps\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import platform\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    ")\n",
    "\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"NVIDIA/CUDA GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AVAILABLE\")\n",
    "print(f\"Target device is {device}\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Loading and Preparing the Dataset**\n",
    "\n",
    "In this section, we load a preprocessed Kubernetes dataset containing event information and operational metrics. We then aggregate event-related columns into a single target column, `event_message`, which simplifies our classification task. This column is encoded into numerical values, making it ready for use with our BERT model.\n",
    "\n",
    "### **Why Aggregate Event Columns?**\n",
    "Kubernetes generates multiple event-related metrics, often represented across several columns. For example:\n",
    "- `event_message_Completed`\n",
    "- `event_message_Failed`\n",
    "- `event_message_Killed`\n",
    "\n",
    "By aggregating these columns into a single `event_message` column, we:\n",
    "1. **Simplify the Classification Task**: The model only needs to classify one target column instead of multiple.\n",
    "2. **Prepare for BERT**: A single target column allows for easier integration with BERT, which expects categorical outputs for classification.\n",
    "\n",
    "### Steps for Dataset Preparation\n",
    "1. **Load the Dataset**:\n",
    "   - Load the dataset from a CSV file, ensuring timestamps are parsed and used as the index.\n",
    "2. **Aggregate Event Columns**:\n",
    "   - Combine event-related columns using the `idxmax` function to extract the most relevant event for each row.\n",
    "   - Clean up the resulting column by removing prefixes (`event_message_` or `event_type_`).\n",
    "3. **Encode Target Labels**:\n",
    "   - Convert the string-based `event_message` column into numerical labels using `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"data/preprocessed_kubernetes_data.csv\"  # Update with the correct path\n",
    "df = pd.read_csv(file_path, parse_dates=[\"timestamp\"], index_col=\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Why Aggregate Event Columns?\n",
    "\n",
    "Kubernetes generates multiple event-related metrics, often represented across several columns. For example:\n",
    "- `event_message_Completed`\n",
    "- `event_message_Failed`\n",
    "- `event_message_Killed`\n",
    "\n",
    "By aggregating these columns into a single `event_message` column, we:\n",
    "1. **Simplify the Classification Task**: The model only needs to classify one target column instead of multiple.\n",
    "2. **Prepare for BERT**: A single target column allows for easier integration with BERT, which expects categorical outputs for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine event-related columns into a single target column\n",
    "event_columns = [\n",
    "    \"event_message_Completed\",\n",
    "    \"event_message_Failed\",\n",
    "    \"event_message_Killed\",\n",
    "    \"event_message_OOMKilled\",\n",
    "    \"event_message_Started\",\n",
    "    \"event_type_Error\",\n",
    "    \"event_type_Normal\",\n",
    "    \"event_type_Warning\",\n",
    "]\n",
    "\n",
    "df[\"event_message\"] = df[event_columns].idxmax(axis=1)  # get the event type\n",
    "df[\"event_message\"] = (\n",
    "    df[\"event_message\"].str.replace(\"event_message_\", \"\").str.replace(\"event_type_\", \"\")\n",
    ")\n",
    "df.drop(columns=event_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Encoding the Target Labels\n",
    "\n",
    "In this step, we transform the event labels (like `Normal`, `Warning`, `Error`) into numeric values. This transformation is necessary because machine learning models, including BERT, work with numerical data, not categorical strings.\n",
    "\n",
    "- **Label Encoding**: The `LabelEncoder` from `sklearn` is used to convert the string labels into integers (e.g., `Normal` -> 0, `Warning` -> 1, `Error` -> 2). This allows the model to understand and process the data.\n",
    "- **BERT Processing**: BERT and other machine learning models expect the target labels to be in a numerical format for tasks like classification. The encoding ensures that the model can learn to predict the correct event type.\n",
    "\n",
    "By encoding the labels, we make the dataset ready for training with a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"event_message_encoded\"] = label_encoder.fit_transform(df[\"event_message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Selecting Features and Target Variable\n",
    "\n",
    "With the target variable (`event_message_encoded`) prepared, we now define the input features (`X`) and target variable (`y`) for training:\n",
    "- **Input Features**:\n",
    "  - Operational metrics that describe the state of the Kubernetes system, such as CPU and memory efficiency, disk I/O, and network latency.\n",
    "- **Target Variable**:\n",
    "  - The encoded `event_message_encoded` column, representing the type of event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"cpu_allocation_efficiency\",\n",
    "    \"memory_allocation_efficiency\",\n",
    "    \"disk_io\",\n",
    "    \"network_latency\",\n",
    "    \"node_temperature\",\n",
    "    \"node_cpu_usage\",\n",
    "    \"node_memory_usage\",\n",
    "]\n",
    "\n",
    "# Select features\n",
    "X = df[numerical_features]\n",
    "y = df[\"event_message_encoded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenizing the Event Messages\n",
    "\n",
    "In this step, we prepare the text data (event messages) for input into the BERT model by using the **BERT tokenizer**. The tokenizer converts the raw text into token IDs that represent words or subwords, allowing BERT to process the text.\n",
    "\n",
    "- **BERT Tokenizer**: The tokenizer splits the event messages into subwords or words and then converts them into corresponding token IDs. This is necessary because BERT understands the text in the form of token IDs, not raw text.\n",
    "- **Padding**: Since BERT expects all input sequences to be of the same length, we apply padding to ensure that all event messages are of uniform length (e.g., 128 tokens). If a message is shorter, it is padded with zeros to match the desired length.\n",
    "- **Attention Masks**: Attention masks indicate which tokens are actual data (1) and which ones are padding (0). This helps the model focus on the real tokens during processing and ignore the padding tokens.\n",
    "\n",
    "By tokenizing, padding, and creating attention masks, we prepare the text data in a format that BERT can efficiently process for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Visualizing the Tokenization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2fc2e18a654abe8507c80f249bbdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Pod restarted due to memory exhaustion.', description='Message:', layout=Layout(width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f4f756c6984f608ca501bd7096028e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Tokenize Message', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization Process:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e60318938a4defbe51fee723e4ea99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Raw Message:</b>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pod restarted due to memory exhaustion.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511bbc0da14f4be78acc5bc23af723b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Tokens:</b>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pod', 'restarted', 'due', 'to', 'memory', 'exhaustion', '.']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067d4fb6041d445db71f5ca8b6a6189c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Token IDs:</b>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17491, 25606, 2349, 2000, 3638, 15575, 1012]\n"
     ]
    }
   ],
   "source": [
    "# from transformers import BertTokenizer\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Sample message for tokenization\n",
    "default_message = \"Pod restarted due to memory exhaustion.\"\n",
    "\n",
    "# Create an input widget for dynamic message input\n",
    "message_input = widgets.Text(\n",
    "    value=default_message,\n",
    "    description=\"Message:\",\n",
    "    layout=widgets.Layout(width=\"100%\"),\n",
    ")\n",
    "\n",
    "# Function to visualize the tokenization process\n",
    "def visualize_tokenization(message):\n",
    "    tokens = tokenizer.tokenize(message)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # Display results\n",
    "    display(widgets.HTML(\"<b>Raw Message:</b>\"))\n",
    "    print(message)\n",
    "    display(widgets.HTML(\"<b>Tokens:</b>\"))\n",
    "    print(tokens)\n",
    "    display(widgets.HTML(\"<b>Token IDs:</b>\"))\n",
    "    print(token_ids)\n",
    "\n",
    "# Button to trigger tokenization visualization\n",
    "tokenize_button = widgets.Button(description=\"Tokenize Message\", button_style=\"info\")\n",
    "\n",
    "# Button event handler\n",
    "def on_tokenize_click(b):\n",
    "    print(\"\\nTokenization Process:\")\n",
    "    visualize_tokenization(message_input.value)\n",
    "\n",
    "\n",
    "# Attach the event handler and display\n",
    "tokenize_button.on_click(on_tokenize_click)\n",
    "display(message_input, tokenize_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Tokenizing Text Data for BERT\n",
    "\n",
    "To prepare textual data for input into the BERT model, the raw text must be converted into a numerical format that the model can understand. This involves three key steps: **tokenization**, **padding**, and **attention masking**.\n",
    "\n",
    "#### 3.2.1 Initialize the BERT Tokenizer\n",
    "The tokenizer from the Hugging Face Transformers library is used to preprocess the text data. It breaks down the text into tokens (subwords) and converts these tokens into numerical IDs.\n",
    "\n",
    "- **Why \"bert-base-uncased\"?**\n",
    "  - This refers to the pretrained BERT model where the tokenizer converts all input text to lowercase and ignores casing distinctions (e.g., \"Pod\" becomes \"pod\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Tokenize the Event Messages\n",
    "Each event message in the dataset is tokenized and converted into token IDs. Additionally, we:\n",
    "1. **Truncate**: Ensure sequences longer than the maximum length are truncated.\n",
    "2. **Pad**: Shorter sequences are padded to a fixed length (e.g., 128 tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the event message (for BERT)\n",
    "X_text = df[\"event_message\"].apply(\n",
    "    lambda x: tokenizer.encode(x, truncation=True, padding=\"max_length\", max_length=128)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3. Padding and Creating Attention Masks**\n",
    "\n",
    "After tokenization, we prepare two key inputs for the BERT model:\n",
    "1. **Padded Sequences**:\n",
    "   - Ensures all sequences are of uniform length by appending zeros to the end of shorter sequences.\n",
    "   - This is necessary because BERT processes batches of data, which require uniform input sizes.\n",
    "2. **Attention Masks**:\n",
    "   - Indicates which tokens in the sequence are actual data (`1`) and which are padding (`0`).\n",
    "   - This helps BERT focus on the relevant tokens and ignore the padding during computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding and attention mask\n",
    "def create_attention_mask(input_ids):\n",
    "    attention_mask = [1 if token_id > 0 else 0 for token_id in input_ids]\n",
    "    return attention_mask\n",
    "\n",
    "\n",
    "X_text_pad = torch.tensor(\n",
    "    [x + [0] * (128 - len(x)) if len(x) < 128 else x[:128] for x in X_text]\n",
    ")  # Padding\n",
    "attention_masks = torch.tensor([create_attention_mask(x) for x in X_text_pad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the BERT Model\n",
    "\n",
    "In this step, we initiate the **training process** for the BERT model. The model learns to classify Kubernetes events based on operational metrics by adjusting its weights to minimize prediction errors.\n",
    "\n",
    "### Key Components of the Training Process:\n",
    "- **Training Loop**: The model is trained over multiple epochs, where each epoch consists of several batches of data. During each epoch, the model learns from the training data and updates its parameters to improve performance.\n",
    "- **tqdm**: We use **tqdm** to track the progress of the training loop. It provides a progress bar that shows the number of batches processed, the current epoch, and key metrics such as loss and accuracy.\n",
    "- **Loss Function**: We use **CrossEntropyLoss** as the loss function. This function computes the difference between the predicted class probabilities and the actual labels, guiding the model in adjusting its parameters to minimize the error.\n",
    "- **Accuracy Calculation**: After each epoch, we calculate the model’s accuracy by comparing its predictions with the true labels. This helps us monitor the model's performance over time.\n",
    "\n",
    "During training, the model adjusts its internal weights to better understand how operational metrics influence event types, improving its ability to classify Kubernetes incidents accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Splitting the Data into Training and Testing Sets\n",
    "\n",
    "In this step, we **split the dataset** into two parts: one for training the model and another for testing its performance. This is essential to evaluate how well the model generalizes to unseen data.\n",
    "\n",
    "### Key Actions:\n",
    "- **train_test_split**: We use the `train_test_split` function from **scikit-learn** to randomly divide the data into training and testing sets. The training set is used to teach the model, while the testing set is used to evaluate the model's performance. We allocate 80% of the data for training and 20% for testing, ensuring a balanced split.\n",
    "- **TensorDataset**: We convert the data into **TensorDataset** objects, which are compatible with PyTorch’s **DataLoader**. This allows the model to efficiently access the training and testing data during training and evaluation.\n",
    "- **DataLoader**: The **DataLoader** provides an iterable over the dataset, splitting it into batches of a specified size (32 in this case). This is crucial for handling large datasets, as it allows the model to process data in manageable chunks, updating its weights incrementally.\n",
    "\n",
    "This step prepares the data for feeding into the BERT model, ensuring that the model can efficiently process both the text data and the operational metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_text_pad, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Convert to TensorDataset for DataLoader\n",
    "train_data = TensorDataset(\n",
    "    X_train, attention_masks[: len(X_train)], torch.tensor(y_train.values)\n",
    ")\n",
    "test_data = TensorDataset(\n",
    "    X_test, attention_masks[len(X_train) :], torch.tensor(y_test.values)\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Initializing the BERT Model for Sequence Classification\n",
    "\n",
    "In this step, we initialize the **BERT model** to perform sequence classification, which is essential for classifying the Kubernetes event types based on the input data.\n",
    "\n",
    "### Key Actions:\n",
    "- **BERT Model Initialization**: We load a pre-trained version of **BERT** (`bert-base-uncased`) using the `BertForSequenceClassification` class. This class is specifically designed for text classification tasks. We set the `num_labels` argument to match the number of unique event types, ensuring the model outputs the correct number of class predictions (e.g., Normal, Warning, Error).\n",
    "- **Adam Optimizer**: The **AdamW** optimizer is used to update the model’s weights during training. We set the learning rate to `1e-5` to ensure the model learns effectively without overshooting the optimal weights. Adam is widely used for its ability to adapt the learning rate for each parameter.\n",
    "- **Moving to GPU/CPU**: The model is moved to the available device (GPU or CPU) using `model.to(device)`. This is important because training deep learning models can be computationally intensive, and using a GPU can significantly speed up the process.\n",
    "\n",
    "By setting up the BERT model in this way, we are ready to begin training it on the dataset to classify the Kubernetes events based on both the text and operational features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/gsampaio/redhat/ai/aiops_101/.venv/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=len(label_encoder.classes_)\n",
    ")\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Training the BERT Model\n",
    "\n",
    "We now train the BERT model using the prepared dataset. The training loop updates the model’s parameters and evaluates its performance over several epochs.\n",
    "\n",
    "### Key Steps\n",
    "1. **Optimizer and Loss Function**:\n",
    "   - **AdamW Optimizer**: Adjusts model weights with a learning rate of `2e-5`, enabling efficient convergence.\n",
    "   - **CrossEntropyLoss**: Calculates the difference between predicted and true labels, suitable for multi-class classification tasks like Kubernetes event prediction.\n",
    "\n",
    "2. **Epoch Loop**:\n",
    "   - The model is trained for **3 epochs** (or fewer in `fast_train` mode). Each epoch processes the entire training dataset, updating the model to minimize loss.\n",
    "\n",
    "3. **Training Data Loop**:\n",
    "   - For each batch of training data:\n",
    "     - Transfer data to the available device (`to(device)`).\n",
    "     - Perform a **forward pass** to compute predictions.\n",
    "     - Calculate the **loss** and perform a **backward pass** to update weights.\n",
    "\n",
    "4. **Performance Tracking**:\n",
    "   - Track **loss** and **accuracy** during training to monitor progress.\n",
    "   - After each epoch, display the average loss and accuracy.\n",
    "\n",
    "5. **Validation**:\n",
    "   - After every epoch, evaluate the model on the **test dataset** to measure generalization.\n",
    "   - Calculate **validation loss** and **accuracy**, similar to training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 375/375 [08:47<00:00,  1.41s/batch]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.0005, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 94/94 [00:13<00:00,  6.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 375/375 [02:45<00:00,  2.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 0.0001, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 94/94 [00:12<00:00,  7.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 375/375 [02:44<00:00,  2.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 0.0000, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 94/94 [00:12<00:00,  7.41batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Set training parameters\n",
    "fast_train = False  # Enable fast training mode\n",
    "epochs = 1 if fast_train else 3  # Use fewer epochs in fast mode\n",
    "\n",
    "# Training loop with tqdm progress bar\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Loop through training data with progress bar\n",
    "    for batch in tqdm(\n",
    "        train_dataloader, desc=f\"Training Epoch {epoch + 1}\", unit=\"batch\"\n",
    "    ):\n",
    "        # Get the data for the current batch\n",
    "        input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get predictions and calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    # Calculate and print the epoch loss and accuracy\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Epoch {epoch + 1} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Validation (optional)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_predictions = 0\n",
    "        for batch in tqdm(test_dataloader, desc=\"Validating\", unit=\"batch\"):\n",
    "            input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            val_correct_predictions += torch.sum(preds == labels)\n",
    "            val_total_predictions += labels.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_dataloader)\n",
    "        val_accuracy = val_correct_predictions / val_total_predictions\n",
    "        print(\n",
    "            f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Model\n",
    "\n",
    "Once the model is trained, it's crucial to evaluate its performance on the **test set**. This evaluation helps us understand how well the model generalizes to new, unseen data. The two primary tools we use for evaluating model performance are **classification reports** and **confusion matrices**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OOMKilled' 'Killed' 'Killed' ... 'Failed' 'Completed' 'OOMKilled']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Convert logits to predicted class labels\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Mapping back the numeric predictions to original class labels\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "y_true_labels = label_encoder.inverse_transform(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Classification Report\n",
    "\n",
    "- The classification report provides a detailed breakdown of the model’s performance across each class (in this case, the different event types).\n",
    "- It includes metrics like **precision**, **recall**, **f1-score**, and **support**:\n",
    "    - **Precision**: The percentage of positive predictions that are correct.\n",
    "    - **Recall**: The percentage of actual positive instances that were correctly identified.\n",
    "    - **F1-score**: The harmonic mean of precision and recall, providing a single metric that balances both.\n",
    "    - **Support**: The number of occurrences of each class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Completed       1.00      1.00      1.00       608\n",
      "      Failed       1.00      1.00      1.00       593\n",
      "      Killed       1.00      1.00      1.00       574\n",
      "   OOMKilled       1.00      1.00      1.00       621\n",
      "     Started       1.00      1.00      1.00       604\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Confusion Matrix:\n",
    "\n",
    "- The confusion matrix visualizes the model’s prediction errors and successes. It shows how many instances from each class were correctly predicted (True Positives and True Negatives) and how many were misclassified (False Positives and False Negatives).\n",
    "- By examining the confusion matrix, we can identify which event types the model struggles to classify, giving insight into areas where the model needs improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Replace 'label_encoder.classes_' with your class names if you have them as a list\n",
    "class_names = label_encoder.classes_  # Real class labels from the LabelEncoder\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Plot the confusion matrix with real labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    conf_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=False,\n",
    "    xticklabels=class_names,  # Add class names as x-axis labels\n",
    "    yticklabels=class_names,  # Add class names as y-axis labels\n",
    "    annot_kws={\"size\": 12},  # Adjust annotation size\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "plt.ylabel(\"True Label\", fontsize=14)\n",
    "plt.title(\"Confusion Matrix\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "In this notebook, we explored how to use **BERT**, a state-of-the-art transformer model, to classify Kubernetes events based on operational metrics and event logs. By leveraging BERT’s ability to understand contextual relationships in text, we demonstrated how transformer models can enhance the accuracy and robustness of event classification tasks in Kubernetes operations.\n",
    "\n",
    "### Key Highlights\n",
    "1. **Effective Use of Transformers**:\n",
    "   - BERT’s self-attention mechanism allows it to capture complex dependencies in event messages, enabling more accurate predictions compared to traditional ML models.\n",
    "2. **Comprehensive Model Evaluation**:\n",
    "   - We evaluated the fine-tuned BERT model using **classification reports** and **confusion matrices**, revealing both strengths and areas for improvement in classification accuracy.\n",
    "3. **Operational Insights**:\n",
    "   - The fine-tuned model provided actionable insights by accurately classifying Kubernetes events like `Warning` and `Error`, which are critical for maintaining cluster health and uptime.\n",
    "\n",
    "### What's Next?\n",
    "In the next notebook, we will:\n",
    "1. **Explore Advanced Transformers**:\n",
    "   - Investigate newer architectures like **RoBERTa** and **GPT** to push the boundaries of classification accuracy.\n",
    "2. **Implement Custom Architectures**:\n",
    "   - Experiment with hybrid models that combine transformer capabilities with domain-specific feature engineering.\n",
    "3. **Focus on Real-World Integration**:\n",
    "   - Develop practical workflows to integrate transformer models with Kubernetes monitoring and alerting systems for automated decision-making.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
